{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlpnLWW7ueVivT2kgBhuR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samikshyasanskruti/Deep-Learning/blob/main/Artificial_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZ95dL6kPS7x"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "def sigmoid_derivative(z):\n",
        "  return z*(1-z)"
      ],
      "metadata": {
        "id": "pKpjivNWPYyX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN:\n",
        "  def __init__(self,input_size,hidden_size,output_size):\n",
        "    #initialise weights\n",
        "    self.weights_input_hidden=np.random.rand(input_size,hidden_size)\n",
        "    self.weights_hidden_output=np.random.rand(hidden_size,output_size)\n",
        "    #initialise biases\n",
        "    self.bias_hidden=np.random.rand((hidden_size))\n",
        "    self.bias_output=np.random.rand((output_size))\n",
        "\n",
        "  def feedforward(self,X):\n",
        "     #hidden layer\n",
        "     self.hidden_layer_input=np.dot(X,self.weights_input_hidden)+self.bias_hidden\n",
        "     self.hidden_layer_output=sigmoid(self.hidden_layer_input)\n",
        "     #output layer\n",
        "     self.output_layer_input=np.dot(self.hidden_layer_output,self.weights_hidden_output)+self.bias_output\n",
        "     self.output=sigmoid(self.output_layer_input)\n",
        "     return self.output\n",
        "\n",
        "  def backpropagation(self,X,y,learning_rate):\n",
        "     #calculate the error\n",
        "     output_error=self.output-y\n",
        "     output_delta=2*output_error*sigmoid_derivative(self.output)\n",
        "\n",
        "     hidden_error=output_delta.dot(self.weights_hidden_output.T)\n",
        "     hidden_delta=2*output_error*sigmoid_derivative(self.hidden_layer_output)\n",
        "\n",
        "     #update weights and biases\n",
        "     self.weights_hidden_output -= self.hidden_layer_output.T.dot(output_delta)*learning_rate\n",
        "     self.bias_output-= np.sum(output_delta,axis=0)*learning_rate\n",
        "\n",
        "     self.weights_input_hidden -= X.T.dot(hidden_delta)*learning_rate\n",
        "     self.bias_hidden-= np.sum(hidden_delta,axis=0)*learning_rate\n",
        "\n",
        "  def train(self,X,y,epochs,learning_rate):\n",
        "    for epoch in range(1,epochs):\n",
        "      self.feedforward(X)\n",
        "      self.backpropagation(X,y,learning_rate)\n",
        "      if epoch% 1000 == 0:\n",
        "        loss=np.mean(np.square(y-self.output))\n",
        "        print(f'Epoch {epoch}, Loss {loss}')"
      ],
      "metadata": {
        "id": "BnNyWlB0QJh2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ =='__main__':\n",
        "  X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "  y=np.array([[0],[1],[1],[0]])\n",
        "\n",
        "\n",
        "  nn=NN(input_size=2,hidden_size=4,output_size=1)\n",
        "\n",
        "  nn.train(X, y, epochs=10000, learning_rate=0.1)\n",
        "  nn.feedforward(X)\n",
        "\n",
        "  print('\\nFinal Probabilities')\n",
        "  print(nn.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wSETXRTR5dU",
        "outputId": "d11f4b11-3266-4fa7-9bc1-a435279346f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000, Loss 0.03468756238851213\n",
            "Epoch 2000, Loss 0.006961695042490571\n",
            "Epoch 3000, Loss 0.0034555014761265784\n",
            "Epoch 4000, Loss 0.002231658894801429\n",
            "Epoch 5000, Loss 0.0016282045390019237\n",
            "Epoch 6000, Loss 0.0012737744266518103\n",
            "Epoch 7000, Loss 0.0010423459785030554\n",
            "Epoch 8000, Loss 0.0008801073955900815\n",
            "Epoch 9000, Loss 0.0007604298279916969\n",
            "\n",
            "Final Probabilities\n",
            "[[0.01463738]\n",
            " [0.97528236]\n",
            " [0.97527992]\n",
            " [0.03519247]]\n"
          ]
        }
      ]
    }
  ]
}